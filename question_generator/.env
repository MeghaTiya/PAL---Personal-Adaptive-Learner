
# Ollama configuration (for local LLM)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b-instruct-q4_K_M

FLASK_ENV=development
FLASK_DEBUG=True

MAX_CONTENT_LENGTH=524288000  # 500MB in bytes

# Server configuration
HOST=0.0.0.0
PORT=5000
